---
title: "kikuChen10"
author: "Viviantsui0514"
date: "2018年3月22日"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# kikuChen ten fb posts in 2017

## Get page posts
```{r cars}
library(Rfacebook)
token <- "EAACEdEose0cBAA2bnAj31pDPyRfXPRXs3myvWhqO4PfGU0skSbrPRAE5FZBRbc88oI7lNwlf0UZCv2SuDa5IWtAmCnKms5w2t4MQEHeKnInlTOHzQkXdqEVOhRsIeeNtZBJXJVQR72IyZCK5hXhSLuSWPEXVVeZAF5IUaqY9Yzz6ZA2GzQAi2sswhlUNZA1q4sM640a8CRr6wZDZD"
me <- getUsers("me", token, private_info = TRUE)
me$name
page.id <- "232716627404" 
page <- getPage(page.id, token=token, n = 10, since= "2017/01/01",until = "2017/12/31")
str(page)
View(page)
```

## Data cleaning
```{r pressure, echo=FALSE}
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(slam)
library(RColorBrewer)
library(wordcloud)

docs <- Corpus(VectorSource(page$message))
toSpace <- content_transformer(function(x, pattern) {
  return (gsub(pattern, " ", x))}
)
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "與")
docs <- tm_map(docs, toSpace, "為")
docs <- tm_map(docs, toSpace, "我們")
docs <- tm_map(docs, toSpace, "及")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs

```

## Word cloud
````{r}
mixseg = worker()
jieba_tokenizer=function(d){
  unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[-c(1:34),]
wordcloud(freqFrame$Var1,freqFrame$Freq,
          scale=c(5,0.5),min.freq=10,max.words=50,
          random.order=FALSE, random.color=TRUE, 
          rot.per=0, colors=brewer.pal(8, "Dark2"),
          ordered.colors=FALSE,use.r.layout=FALSE,
          fixed.asp=TRUE)
```
